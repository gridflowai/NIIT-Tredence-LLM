{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60b51d2-52b2-4afd-997e-d6252d4dd15a",
   "metadata": {},
   "source": [
    "#### Messages in Chat Models\n",
    "\n",
    "Messages are the fundamental units of communication in chat models. They represent the input and output of a chat model, along with any additional context or metadata related to a conversation.\n",
    "\n",
    "##### Each message comprises the following components:\n",
    "\n",
    "- **Role**: The function of the message (e.g., \"user\", \"assistant\").\n",
    "- **Content**: The message content (e.g., text, multimodal data).\n",
    "- **Additional Metadata**: Information such as ID, name, token usage, and other model-specific details.\n",
    "\n",
    "##### Components of a Message\n",
    "\n",
    "**Role**\n",
    "Roles distinguish between various types of messages in a conversation, guiding the chat model's responses.\n",
    "\n",
    "| Role       | Description                                                                                     |\n",
    "|------------|-------------------------------------------------------------------------------------------------|\n",
    "| **system** | Provides behavioral guidance to the chat model and additional context (not universally supported). |\n",
    "| **user**   | Represents user input, typically in text or interactive forms.                                 |\n",
    "| **assistant**| Represents the model's response, which may include text or tool invocation requests.            |\n",
    "| **tool**   | Passes results of a tool invocation back to the model after external processing (for models that support tool calling). |\n",
    "| **function (legacy)**| Corresponds to OpenAI's legacy function-calling API; the \"tool\" role is preferred.       |\n",
    "\n",
    "**Content**\n",
    "The content of a message can be either text or a structured list representing multimodal data (e.g., images, audio, video). The format varies by chat model provider.\n",
    "\n",
    "- Most chat models primarily support text content, with some also accommodating multimodal data, though support remains limited across providers.\n",
    "\n",
    "##### Other Message Data\n",
    "Messages may also include additional information depending on the provider:\n",
    "\n",
    "- **ID**: An optional unique identifier for the message.\n",
    "- **Name**: An optional property to distinguish between entities/speakers sharing the same role (not all models support this).\n",
    "- **Metadata**: Extra information about the message, such as timestamps and token usage.\n",
    "- **Tool Calls**: Requests made by the model to call one or more tools (see tool calling for more information).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48175b31-a6f7-4084-bb06-4a911a41b041",
   "metadata": {},
   "source": [
    "#### SystemMessage in Chat Models\n",
    "\n",
    "- A SystemMessage is utilized to prime the behavior of the AI model and provide additional context. \n",
    "- It can instruct the model to adopt a specific persona or set the tone of the conversation (e.g., \"This is a conversation about cooking\").\n",
    "\n",
    "`Support for System Messages` - Different chat providers may support system messages in one of the following ways:\n",
    "\n",
    "- **Through a \"system\" message role**: The system message is included in the message sequence with the role explicitly set to \"system.\"\n",
    "  \n",
    "- **Through a separate API parameter for system instructions**: Instead of being included as a message, system instructions are provided via a dedicated API parameter.\n",
    "  \n",
    "- **No support for system messages**: Some models do not support system messages at all.\n",
    "\n",
    "Most major chat model providers support system instructions either as a chat message or through a separate API parameter. \n",
    "\n",
    "`LangChain Behavior`\n",
    "\n",
    "- LangChain will automatically adapt to the capabilities of the provider\n",
    "- If the provider supports a separate API parameter for system instructions, LangChain will extract the content of a system message and pass it through that parameter.\n",
    "- If no system message is supported by the provider, LangChain will typically attempt to incorporate the system message content into a HumanMessage. If that is not feasible, it may raise an exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5648c477-de43-4463-85d9-a948f34851e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43e99fb-4dbc-40d2-a7ab-df3d8a1bca3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Hello! How can I assist you today?',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 9,\n",
       "   'prompt_tokens': 18,\n",
       "   'total_tokens': 27,\n",
       "   'completion_tokens_details': {'audio_tokens': None,\n",
       "    'reasoning_tokens': 0,\n",
       "    'accepted_prediction_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-57ce8746-5d4a-4ee2-a883-98eeffea7ec9-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 18,\n",
       "  'output_tokens': 9,\n",
       "  'total_tokens': 27,\n",
       "  'input_token_details': {'cache_read': 0},\n",
       "  'output_token_details': {'reasoning': 0}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  # Assuming you're using a chat model like OpenAI\n",
    "\n",
    "# Define the chat model\n",
    "model = ChatOpenAI()  # Initialize your chat model here (e.g., ChatOpenAI or another supported model)\n",
    "\n",
    "# Prepare the messages\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant! Your name is Bob.\"\n",
    "    ),\n",
    "\n",
    "]\n",
    "\n",
    "# Invoke the model with the messages and print the response\n",
    "response = model.invoke(messages)\n",
    "dict(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600775fc-28fd-4a68-a8db-e670c92dac48",
   "metadata": {},
   "source": [
    "#### Human messages\n",
    "\n",
    "The HumanMessage represents input from the user interacting with the chat model. \n",
    "It corresponds to the \"user\" role in the conversation and is used to convey questions, \n",
    "requests, or any other form of communication directed toward the model. \n",
    "\n",
    "##### Key Features:\n",
    "- **Role**: Identifies the message as coming from the user.\n",
    "- **Content**: Contains the text or data that the user wishes to communicate to the model.\n",
    "\n",
    "##### Usage Example:\n",
    "```python\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a human message\n",
    "user_message = HumanMessage(\n",
    "    content=\"Can you help me with my project?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a57b84-e7fb-40d7-87cc-d7573bfcdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd02e9f2-6f9e-4326-ae3b-cf22e048c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant! Your name is Bob.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is your name?\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09823ef8-7661-4b10-a646-307a509db275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! My name is Bob. How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model with the messages and print the response\n",
    "response = model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb55bb8-e93b-4b43-8630-a233edc03882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
