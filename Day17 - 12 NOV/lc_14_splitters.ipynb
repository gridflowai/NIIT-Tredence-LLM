{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae986566-e797-4ee4-8445-d6bd1b82de5c",
   "metadata": {},
   "source": [
    "#### Splitters\n",
    "\n",
    "#### Reasons to Split Documents:\n",
    "\n",
    "- **Handle Non-Uniform Document Lengths**: Documents in real-world collections vary greatly in size. Splitting helps maintain consistent processing across all documents.\n",
    "  \n",
    "- **Overcome Model Input Size Constraints**: Many language and embedding models have maximum input limits. Splitting enables us to process larger documents that would otherwise exceed these restrictions.\n",
    "  \n",
    "- **Improve Representation Quality**: For longer documents, embeddings or representations may lose quality when capturing excessive information. Splitting allows for more focused, accurate representations of each part.\n",
    "  \n",
    "- **Enhance Retrieval Precision**: In retrieval systems, splitting enables more granular search results, allowing for precise matching between query terms and relevant document sections.\n",
    "  \n",
    "- **Optimize Computational Resources**: Processing smaller text chunks can save memory and allow for better parallelization, making processing tasks more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d323b-bcf9-44d3-b0cd-fe00bac3646a",
   "metadata": {},
   "source": [
    "1. Length based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93add97c-7e71-49b6-90c1-71de284bda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c790516a-e49e-4a4c-b78b-fc335674f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./state_of_the_union.txt\", encoding=\"utf-8\") as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52c2f19-91e3-4982-b211-c00dcdcae491",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name = \"cl100k_base\", \n",
    "    chunk_size    = 100, \n",
    "    chunk_overlap = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcee6591-fee3-42e6-b71c-bdca99896e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7967ca-dc17-4f08-a118-c16776319ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bd28eb-d251-4b7a-ac43-45de3a044dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41014cc4-22cb-4891-aaa4-22611e75cc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution.',\n",
       " 'And with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18d6ba4-3ec1-4296-a6d8-41bde3f8d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913e7a4f-a45c-4cdb-ad2b-250509fd029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842ad561-0978-49a7-b6ad-0e44c41d7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b562a84-d0bb-49d8-8a84-0a193e300d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7bc2c5-0bae-44ef-9e82-67231b5f3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "390b9e55-fb92-44ea-903b-0e14606f4382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e62544-7e88-4e7e-bd81-6f8648a995dd",
   "metadata": {},
   "source": [
    "#### Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e2a770b-ac72-4629-85d9-1a17070dc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade --quiet  spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3903325c-432d-4b67-a790-89a213f0deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SpacyTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a2433b7-4b71-4cb1-928a-9aac7a995db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SpacyTextSplitter(chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bff1d4d6-4ba7-4ef5-810b-478a0d032d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman.\n",
      "\n",
      "Members of Congress and the Cabinet.\n",
      "\n",
      "Justices of the Supreme Court.\n",
      "\n",
      "My fellow Americans.  \n",
      "\n",
      "\n",
      "\n",
      "Last year COVID-19 kept us apart.\n",
      "\n",
      "This year we are finally together again. \n",
      "\n",
      "\n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents.\n",
      "\n",
      "But most importantly as Americans. \n",
      "\n",
      "\n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "\n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "\n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways.\n",
      "\n",
      "But he badly miscalculated. \n",
      "\n",
      "\n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over.\n",
      "\n",
      "Instead he met a wall of strength he never imagined. \n",
      "\n",
      "\n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "\n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA3\\envs\\langchain_env\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e13fc1-698c-408c-9f8e-82f0e24bbdf8",
   "metadata": {},
   "source": [
    "#### Sentence Transformers\n",
    "\n",
    "- a BERT model (embeddings)\n",
    "\n",
    "- The SentenceTransformersTokenTextSplitter is a specialized text splitter for use with the sentence-transformer models.\n",
    "- The default behaviour is to split the text into chunks that fit the token window of the sentence transformer model that you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36117a6-6d7c-42cc-a014-be466ec5b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3af7432f-2f88-42f4-95e5-2ef2ed0df159",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceTransformersTokenTextSplitter(model_name      = 'all-MiniLM-L6-v2', \n",
    "                                                 chunk_overlap   = 0, \n",
    "                                                 tokens_per_chunk= 5,\n",
    "                                                 #cache_dir       = r'D:\\AI-DATASETS\\07-Hugging-Face-Data'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8267a17d-667f-49bc-a92c-11dc3f913c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your text\n",
    "dummy_text = \"This is an example sentence for tokenization using SentenceTransformers. It demonstrates splitting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "897c3131-98dd-4346-8c5f-4988df500171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.count_tokens(text=dummy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d916ffcb-728f-46b9-a594-c70da6c7e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is an example sentence',\n",
       " 'for tokenization using sentence',\n",
       " '##transformers.',\n",
       " 'it demonstrates splitting.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sentence into tokens\n",
    "tokens = splitter.split_text(dummy_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cba7a-b69a-42c9-a752-09a0e572a246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
