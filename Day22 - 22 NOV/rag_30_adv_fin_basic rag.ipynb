{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a06a4a8-8ff5-4ea0-9a7f-44455d4bd8cb",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "#### Retrivals using embeddings (key points)\n",
    "-----------------------------------\n",
    "\n",
    "**Dataset**\n",
    "- PDF file on MS annual report (2022)\n",
    "    - plain text\n",
    "    - tables\n",
    "    - Plots/graphs\n",
    "    \n",
    "**Extract data**\n",
    "- Extract text pages\n",
    "\n",
    "**Chunking**\n",
    "- Two-Step Chunking Strategy: LangChain + SentenceTransformersTokenTextSplitter\n",
    "\n",
    "**Embeddings**\n",
    "- sentence transformer (from chromadb)\n",
    "\n",
    "**Vector database**\n",
    "- in memory chromadb\n",
    "\n",
    "**Query**\n",
    "- Using embeddings\n",
    "- Using RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb3b2f6-6609-4d65-a019-9f368dda92ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3ae9d0-0e4a-4ac2-9ec5-e66617ae8933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62aa28f5-20c2-495f-a11a-9c7e086b64bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pdfreader\n",
    "#!pip install PypDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9531164-80c9-4121-9435-c91cef34e723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da377cd-96a6-4e96-a370-cc924358f218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ab272c-88d1-444c-ae93-37fa27f01a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06fe869-b8cc-4a56-85dd-1db4f6697b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = PdfReader(r\".\\data\\microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec75a6d0-42f2-4189-acef-e2ef6524812f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bd6463-cd0e-4b5e-8903-36f840fc5ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35306d0a-dcd0-4a5b-8531-73f7711f6d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049a5de-8b85-49c3-95d6-a7289ddc27b2",
   "metadata": {},
   "source": [
    "**RecursiveCharacterTextSplitter**\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` is a utility that helps split long text into smaller chunks while maintaining as much context as possible. Here's how it works:\n",
    "\n",
    "##### Separators\n",
    "\n",
    "The `separators` list defines the order in which the text will be split. In this example:\n",
    "\n",
    "- It first attempts to split by two newlines (`\"\\n\\n\"`), which typically indicates a paragraph break.\n",
    "- If the chunk size condition isn't met, it moves on to split by a single newline (`\"\\n\"`), indicating line breaks or new sentences.\n",
    "- Then it tries to split by period followed by a space (`\". \"`), which indicates sentence boundaries.\n",
    "- After that, it splits by a space (`\" \"`), which breaks the text at the word level.\n",
    "- Finally, it splits by individual characters (`\"\"`) if none of the above yield a chunk that meets the size requirement.\n",
    "\n",
    "##### Chunk size and overlap\n",
    "\n",
    "- `chunk_size=1000` means that each chunk will have a maximum of 1000 characters.\n",
    "- `chunk_overlap=0` means there will be no overlap between consecutive chunks (i.e., no repeated content).\n",
    "\n",
    "##### Recursive splitting\n",
    "\n",
    "The process is recursive because it starts from the largest separator (paragraphs), and if the resulting chunk is still larger than 1000 characters, it moves down to the next smaller separator (sentences, words, etc.), ensuring that the chunks are as close to 1000 characters as possible while retaining coherent pieces of text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b401d2-56bc-4b4c-ae88-0612b921ec4a",
   "metadata": {},
   "source": [
    "```python\n",
    "text = \"This is a long paragraph with multiple sentences. It discusses several topics and ideas, flowing continuously. For instance, it talks about machine learning, deep learning, and various AI applications. While doing so, it doesn’t include paragraph breaks or line breaks. Everything is packed in a single block.\"\n",
    "```\n",
    "\n",
    "##### Initial Split\n",
    "It tries to split using `\"\\n\\n\"` (paragraph breaks). There are no `\\n\\n` in this text, so no split happens.\n",
    "\n",
    "##### Next Split\n",
    "It then looks for `\"\\n\"` (line breaks). There are none here either.\n",
    "\n",
    "##### Next Split\n",
    "It tries `\". \"` (sentence breaks). Here, it successfully splits the text into three sentences:\n",
    "- \"This is a long paragraph with multiple sentences.\"\n",
    "- \"It discusses several topics and ideas, flowing continuously.\"\n",
    "- \"For instance, it talks about machine learning, deep learning, and various AI applications.\"\n",
    "- \"While doing so, it doesn’t include paragraph breaks or line breaks. Everything is packed in a single block.\"\n",
    "\n",
    "##### Final Chunks\n",
    "If any of these sentences exceed 1000 characters, it continues splitting by `\" \"` (spaces) and eventually by characters if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5e138-bd01-4f6b-bce9-e0d708390a23",
   "metadata": {},
   "source": [
    "```python\n",
    "text = \"\"\"Data science is an interdisciplinary field that uses various techniques to extract insights from data. It involves statistics, machine learning, and data analysis.\n",
    "\n",
    "Machine learning is a subset of AI that enables systems to learn from data and improve from experience.\n",
    "\n",
    "Deep learning, a branch of machine learning, uses neural networks to model complex patterns in data.\"\"\"\n",
    "```\n",
    "\n",
    "##### Initial Split\n",
    "The first separator `\"\\n\\n\"` (paragraph breaks) will be applied:\n",
    "- \"Data science is an interdisciplinary field that uses various techniques to extract insights from data. It involves statistics, machine learning, and data analysis.\"\n",
    "- \"Machine learning is a subset of AI that enables systems to learn from data and improve from experience.\"\n",
    "- \"Deep learning, a branch of machine learning, uses neural networks to model complex patterns in data.\"\n",
    "\n",
    "##### Next Split\n",
    "If any paragraph exceeds 1000 characters, it would then try to split further using `\"\\n\"`, `\". \"`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a205daa-c3d6-4c66-a2a6-79c10bf4b749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80507da8-2fdf-40df-b42c-6303de07277e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators   = [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size   = 1000,\n",
    "    chunk_overlap= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2aaec2b-1d2d-473f-95a4-f26777ee1f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e672aa-4b52-4c06-ba44-8847cba3aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 344\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459ebb-787e-4177-9b04-89065fb652ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
