{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uZ9wExEBab4c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "X = torch.randn(100, 10)  # 100 samples, 10 features\n",
        "y = X @ torch.randn(10, 1) * 2 + torch.randn(100, 1) * 0.5  # Linear relation with noise"
      ],
      "metadata": {
        "id": "GT6hfq0tcduW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.W = nn.Parameter(torch.randn(input_dim, output_dim))  # Weight matrix W (d_in x d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x @ self.W"
      ],
      "metadata": {
        "id": "SK5lyMz3cdrg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel(input_dim=10, output_dim=1)"
      ],
      "metadata": {
        "id": "BtUmvcBicdm7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "VSxN6SE8cx97"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_full_model(model, X, y, optimizer, loss_fn, num_epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(X)\n",
        "\n",
        "        loss   = loss_fn(output, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GSmamqiccx6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune full model (W)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "train_full_model(model, X, y, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "ePbwELBkcx3i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the original W after fine-tuning\n",
        "W_fine_tuned = model.W.clone()"
      ],
      "metadata": {
        "id": "kwnjjx0Ncx0n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, applying LoRA (using low-rank matrices A and B)\n",
        "rank = 2  # Low-rank approximation"
      ],
      "metadata": {
        "id": "bvpg28_LcxxK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = nn.Parameter(torch.randn(10, rank))  # A (d_in x r)\n",
        "B = nn.Parameter(torch.randn(rank, 1))   # B (r x d_out) corrected to (2, 1) for matrix multiplication"
      ],
      "metadata": {
        "id": "B1UFWKqZcxtv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new model with LoRA modification\n",
        "class LoRAModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, A, B):\n",
        "        super(LoRAModel, self).__init__()\n",
        "        self.A = A  # Low-rank matrix A\n",
        "        self.B = B  # Low-rank matrix B\n",
        "        self.W_base = nn.Parameter(torch.randn(input_dim, output_dim))  # Base weight W (d_in x d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply LoRA (W' = W_base + AB^T)\n",
        "        W_prime = self.W_base + torch.matmul(self.A, self.B)  # Corrected: A (d_in, r) and B.T (r, d_out)\n",
        "        return x @ W_prime"
      ],
      "metadata": {
        "id": "dLwy8gWndWPm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LoRA model\n",
        "lora_model = LoRAModel(input_dim=10, output_dim=1, A=A, B=B)"
      ],
      "metadata": {
        "id": "GV1R6-7ndWLE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LoRA model (fine-tune A and B)\n",
        "def train_lora_model(model, X, y, optimizer, loss_fn, num_epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = loss_fn(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "1oHz2fxSdWHY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune LoRA model (A and B)\n",
        "optimizer = optim.SGD([lora_model.A, lora_model.B], lr=0.01)  # Using lora_model.A and lora_model.B\n",
        "\n",
        "train_lora_model(lora_model, X, y, optimizer, loss_fn)\n"
      ],
      "metadata": {
        "id": "DiMaRPDGdk1n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the W_prime after fine-tuning LoRA\n",
        "W_prime_fine_tuned = lora_model.W_base + torch.matmul(lora_model.A, lora_model.B)"
      ],
      "metadata": {
        "id": "Kz4EDs-8dkyW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the results\n",
        "print(\"Fine-tuned W from full model:\\n\", W_fine_tuned)\n",
        "print(\"Fine-tuned W' from LoRA model (W_base + AB^T):\\n\", W_prime_fine_tuned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HRVdEzQdkvE",
        "outputId": "29d11742-02da-448d-c560-8db3f0c1d0a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned W from full model:\n",
            " tensor([[ 0.7774],\n",
            "        [ 1.6432],\n",
            "        [ 0.0985],\n",
            "        [ 1.9516],\n",
            "        [ 0.3730],\n",
            "        [ 2.6920],\n",
            "        [-5.2525],\n",
            "        [-4.1507],\n",
            "        [ 0.0789],\n",
            "        [-0.0585]], grad_fn=<CloneBackward0>)\n",
            "Fine-tuned W' from LoRA model (W_base + AB^T):\n",
            " tensor([[ 0.5844],\n",
            "        [ 1.4381],\n",
            "        [-0.4161],\n",
            "        [ 2.4815],\n",
            "        [ 0.5286],\n",
            "        [ 3.0505],\n",
            "        [-6.1518],\n",
            "        [-4.9549],\n",
            "        [ 0.3103],\n",
            "        [-0.0373]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the results are similar (using Frobenius norm of difference)\n",
        "difference = torch.norm(W_fine_tuned - W_prime_fine_tuned)\n",
        "print(f\"Difference between fine-tuned W and W' (Frobenius norm): {difference.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRaPATAxdkrR",
        "outputId": "b5698612-30a1-42dd-c6c4-bde76bef1f1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference between fine-tuned W and W' (Frobenius norm): 1.5123080015182495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJ37W6Rldkn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1zHMuvwdWEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}